{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 财务舞弊识别集成学习框架\n",
    "\n",
    "本Notebook实现了基于XGBoost、LightGBM和CatBoost的集成学习模型，用于财务舞弊检测。\n",
    "包含以下主要功能：\n",
    "1. 数据加载与预处理\n",
    "2. 混合采样方法处理不平衡数据\n",
    "3. 使用Optuna进行贝叶斯超参数优化\n",
    "4. 加权软投票集成方法\n",
    "5. 堆叠集成(Stacking)方法\n",
    "6. 模型性能比较与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import optuna\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载成功，共有 119060 行和 31 列\n",
      "训练集大小: 95248，测试集大小: 23812\n",
      "原始训练集类别分布： Counter({0: 81458, 1: 13790})\n",
      "原始测试集类别分布： Counter({0: 20365, 1: 3447})\n",
      "训练集不平衡比例（负样本/正样本）：5.91\n"
     ]
    }
   ],
   "source": [
    "# 假设数据已经预处理并保存为CSV文件\n",
    "try:\n",
    "    data = pd.read_csv('reduced_data.csv')\n",
    "    print('数据加载成功，共有 {} 行和 {} 列'.format(data.shape[0], data.shape[1]))\n",
    "except Exception as e:\n",
    "    print('数据加载失败: {}'.format(e))\n",
    "\n",
    "\n",
    "# 分离特征和标签\n",
    "X = data.drop(['Stkcd', 'Accper', 'Typrep ', 'isviolation'], axis=1)\n",
    "y = data['isviolation']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('训练集大小: {}，测试集大小: {}'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "# 查看类别分布\n",
    "print('原始训练集类别分布：', Counter(y_train))\n",
    "print('原始测试集类别分布：', Counter(y_test))\n",
    "\n",
    "# 计算不平衡比例\n",
    "neg_count = sum(y_train == 0)\n",
    "pos_count = sum(y_train == 1)\n",
    "imbalance_ratio = neg_count / pos_count\n",
    "print('训练集不平衡比例（负样本/正样本）：{:.2f}'.format(imbalance_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 混合采样方法处理数据不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采样后训练集类别分布： Counter({0: 41370, 1: 27580})\n",
      "采样后不平衡比例：1.50\n"
     ]
    }
   ],
   "source": [
    "# 混合采样策略：先过采样，再欠采样\n",
    "over_strategy = {1: min(int(pos_count * 2), neg_count - 100)}  # 过采样正样本到负样本的一半\n",
    "under_strategy = {0: int(over_strategy[1] * 1.5)}  # 欠采样负样本到正样本的1.5倍\n",
    "\n",
    "# 创建采样管道\n",
    "over_sampler = SMOTE(random_state=42, sampling_strategy=over_strategy)\n",
    "under_sampler = RandomUnderSampler(random_state=42, sampling_strategy=under_strategy)\n",
    "\n",
    "# 先过采样，再过欠采样\n",
    "X_train_resampled, y_train_resampled = over_sampler.fit_resample(X_train, y_train)\n",
    "X_train_resampled, y_train_resampled = under_sampler.fit_resample(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print('采样后训练集类别分布：', Counter(y_train_resampled))\n",
    "print('采样后不平衡比例：{:.2f}'.format(sum(y_train_resampled == 0) / sum(y_train_resampled == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 13:28:29,082] A new study created in memory with name: no-name-99bba749-0e9b-437d-9ad9-984d596a1556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始XGBoost参数优化（缩小范围+无早停）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 13:29:00,991] Trial 1 finished with value: 0.8484106740460179 and parameters: {'n_estimators': 516, 'max_depth': 13, 'learning_rate': 0.23808831490597251, 'subsample': 0.8905149147302976, 'colsample_bytree': 0.7390922645435068, 'gamma': 0.07086812708644882, 'min_child_weight': 9, 'reg_alpha': 4.821403174849755, 'reg_lambda': 3.4503765320212927}. Best is trial 1 with value: 0.8484106740460179.\n",
      "[I 2025-11-20 13:29:02,611] Trial 0 finished with value: 0.8515065107014298 and parameters: {'n_estimators': 519, 'max_depth': 13, 'learning_rate': 0.23638437235537466, 'subsample': 0.8901637561172621, 'colsample_bytree': 0.7446828419788466, 'gamma': 0.05714831910327781, 'min_child_weight': 8, 'reg_alpha': 4.7754252419124406, 'reg_lambda': 3.368687440544859}. Best is trial 0 with value: 0.8515065107014298.\n",
      "[I 2025-11-20 13:29:29,891] Trial 2 finished with value: 0.8505954512023916 and parameters: {'n_estimators': 502, 'max_depth': 14, 'learning_rate': 0.23078869247899225, 'subsample': 0.8801625121380151, 'colsample_bytree': 0.7385614615154276, 'gamma': 0.07640994559433083, 'min_child_weight': 8, 'reg_alpha': 4.805540444442717, 'reg_lambda': 3.439385936019169}. Best is trial 0 with value: 0.8515065107014298.\n",
      "[I 2025-11-20 13:29:30,091] Trial 3 finished with value: 0.8495674515966978 and parameters: {'n_estimators': 508, 'max_depth': 13, 'learning_rate': 0.2452301698653143, 'subsample': 0.8980607284427747, 'colsample_bytree': 0.7470061479762656, 'gamma': 0.08798068853688909, 'min_child_weight': 8, 'reg_alpha': 4.765596966287106, 'reg_lambda': 3.4645978171433307}. Best is trial 0 with value: 0.8515065107014298.\n",
      "[I 2025-11-20 13:29:58,470] Trial 5 finished with value: 0.849969023642538 and parameters: {'n_estimators': 522, 'max_depth': 13, 'learning_rate': 0.24639269878272935, 'subsample': 0.8881459849583986, 'colsample_bytree': 0.7490686138686318, 'gamma': 0.062092387348685885, 'min_child_weight': 9, 'reg_alpha': 4.889455007193826, 'reg_lambda': 3.468595025676245}. Best is trial 0 with value: 0.8515065107014298.\n",
      "[I 2025-11-20 13:29:58,990] Trial 4 finished with value: 0.8515854278241285 and parameters: {'n_estimators': 518, 'max_depth': 14, 'learning_rate': 0.2307560799918224, 'subsample': 0.8905271407155209, 'colsample_bytree': 0.7379840515401548, 'gamma': 0.06122946594196165, 'min_child_weight': 8, 'reg_alpha': 4.812261543712729, 'reg_lambda': 3.346878867455758}. Best is trial 4 with value: 0.8515854278241285.\n",
      "[I 2025-11-20 13:30:26,576] Trial 6 finished with value: 0.8486317284046562 and parameters: {'n_estimators': 510, 'max_depth': 14, 'learning_rate': 0.23209939937518934, 'subsample': 0.8882560887832089, 'colsample_bytree': 0.7464786924728777, 'gamma': 0.0899750254985716, 'min_child_weight': 9, 'reg_alpha': 4.846907035659936, 'reg_lambda': 3.442471470528821}. Best is trial 4 with value: 0.8515854278241285.\n",
      "[I 2025-11-20 13:30:27,315] Trial 7 finished with value: 0.8502260914547248 and parameters: {'n_estimators': 526, 'max_depth': 14, 'learning_rate': 0.23320051565293307, 'subsample': 0.8831768083473728, 'colsample_bytree': 0.7403925998144395, 'gamma': 0.0812104319744084, 'min_child_weight': 9, 'reg_alpha': 4.868664098750679, 'reg_lambda': 3.3004565389368667}. Best is trial 4 with value: 0.8515854278241285.\n",
      "[I 2025-11-20 13:30:54,291] Trial 9 finished with value: 0.8504295006270531 and parameters: {'n_estimators': 510, 'max_depth': 14, 'learning_rate': 0.2496255619069804, 'subsample': 0.8882654685835365, 'colsample_bytree': 0.7345951319787697, 'gamma': 0.0960535322287237, 'min_child_weight': 8, 'reg_alpha': 4.708871213680563, 'reg_lambda': 3.4182825473079026}. Best is trial 4 with value: 0.8515854278241285.\n",
      "[I 2025-11-20 13:30:54,313] Trial 8 finished with value: 0.8487534880215506 and parameters: {'n_estimators': 518, 'max_depth': 14, 'learning_rate': 0.2310516552790936, 'subsample': 0.8893759100552145, 'colsample_bytree': 0.7357286616738172, 'gamma': 0.09769333596611617, 'min_child_weight': 9, 'reg_alpha': 4.875894816925167, 'reg_lambda': 3.32975493585634}. Best is trial 4 with value: 0.8515854278241285.\n",
      "[I 2025-11-20 13:31:24,156] Trial 10 finished with value: 0.8521097199822693 and parameters: {'n_estimators': 519, 'max_depth': 14, 'learning_rate': 0.23251190776787203, 'subsample': 0.8938343037487109, 'colsample_bytree': 0.7468367056716029, 'gamma': 0.056848910636022015, 'min_child_weight': 8, 'reg_alpha': 4.803407136484223, 'reg_lambda': 3.4661496189005994}. Best is trial 10 with value: 0.8521097199822693.\n",
      "[I 2025-11-20 13:31:24,336] Trial 11 finished with value: 0.8512075295972927 and parameters: {'n_estimators': 529, 'max_depth': 14, 'learning_rate': 0.24209810493819667, 'subsample': 0.8965441694091516, 'colsample_bytree': 0.7301192724119029, 'gamma': 0.05082712509824371, 'min_child_weight': 8, 'reg_alpha': 4.719486728502613, 'reg_lambda': 3.3748991099513685}. Best is trial 10 with value: 0.8521097199822693.\n",
      "[I 2025-11-20 13:31:55,000] Trial 12 finished with value: 0.8529611029823302 and parameters: {'n_estimators': 530, 'max_depth': 14, 'learning_rate': 0.2352126104186026, 'subsample': 0.8961185528547606, 'colsample_bytree': 0.7303698751544976, 'gamma': 0.050879559154835045, 'min_child_weight': 8, 'reg_alpha': 4.76721529233421, 'reg_lambda': 3.3814729277275077}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 13:31:55,066] Trial 13 finished with value: 0.852580220174442 and parameters: {'n_estimators': 524, 'max_depth': 14, 'learning_rate': 0.23520955128831492, 'subsample': 0.8939615621172501, 'colsample_bytree': 0.7434518326608247, 'gamma': 0.06534695123369225, 'min_child_weight': 8, 'reg_alpha': 4.770729470952786, 'reg_lambda': 3.381183103004571}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 13:32:24,878] Trial 14 finished with value: 0.8521351226061208 and parameters: {'n_estimators': 525, 'max_depth': 14, 'learning_rate': 0.23581812317853518, 'subsample': 0.895132597896078, 'colsample_bytree': 0.730421675842749, 'gamma': 0.05033673595030235, 'min_child_weight': 8, 'reg_alpha': 4.7558178842410825, 'reg_lambda': 3.4947949602974213}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 13:32:24,971] Trial 15 finished with value: 0.8519570089913923 and parameters: {'n_estimators': 530, 'max_depth': 14, 'learning_rate': 0.2362788261245134, 'subsample': 0.8941543482691782, 'colsample_bytree': 0.7420986613723216, 'gamma': 0.0688822501825191, 'min_child_weight': 8, 'reg_alpha': 4.748399333848602, 'reg_lambda': 3.4036573999067103}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 13:32:57,254] Trial 17 finished with value: 0.8517512469245784 and parameters: {'n_estimators': 525, 'max_depth': 14, 'learning_rate': 0.24046223357812097, 'subsample': 0.8994109007625171, 'colsample_bytree': 0.7433450791936395, 'gamma': 0.06492514134849553, 'min_child_weight': 8, 'reg_alpha': 4.782555714086141, 'reg_lambda': 3.3841961043640985}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 13:32:57,301] Trial 16 finished with value: 0.851761620348377 and parameters: {'n_estimators': 530, 'max_depth': 14, 'learning_rate': 0.23995842096140735, 'subsample': 0.8995475432662772, 'colsample_bytree': 0.7424900387802873, 'gamma': 0.06808446631894624, 'min_child_weight': 8, 'reg_alpha': 4.7373533976564834, 'reg_lambda': 3.3962957981578934}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 15:58:34,007] Trial 19 finished with value: 0.8519093893441182 and parameters: {'n_estimators': 523, 'max_depth': 13, 'learning_rate': 0.23432262165855242, 'subsample': 0.8927266521499556, 'colsample_bytree': 0.7329792195572764, 'gamma': 0.0559295879868448, 'min_child_weight': 8, 'reg_alpha': 4.73256886137984, 'reg_lambda': 3.348800402745988}. Best is trial 12 with value: 0.8529611029823302.\n",
      "[I 2025-11-20 15:58:34,264] Trial 18 finished with value: 0.8504317901588941 and parameters: {'n_estimators': 530, 'max_depth': 13, 'learning_rate': 0.23443829130201613, 'subsample': 0.8924570672466945, 'colsample_bytree': 0.7330258550295601, 'gamma': 0.07736576597618819, 'min_child_weight': 8, 'reg_alpha': 4.7338780454014735, 'reg_lambda': 3.3528108051912637}. Best is trial 12 with value: 0.8529611029823302.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【最优交叉验证AUC】: 0.852961\n",
      "【最优参数】:\n",
      "  n_estimators: 530\n",
      "  max_depth: 14\n",
      "  learning_rate: 0.2352126104186026\n",
      "  subsample: 0.8961185528547606\n",
      "  colsample_bytree: 0.7303698751544976\n",
      "  gamma: 0.050879559154835045\n",
      "  min_child_weight: 8\n",
      "  reg_alpha: 4.76721529233421\n",
      "  reg_lambda: 3.3814729277275077\n",
      "\n",
      "【测试集最终AUC】: 0.789192\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- 预划分CV索引 --------------------------\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 确保数据集已定义（请替换为你的实际数据）\n",
    "try:\n",
    "    cv_splits = list(skf.split(X_train_resampled, y_train_resampled))\n",
    "except NameError:\n",
    "    raise NameError(\"请先定义 X_train_resampled、y_train_resampled、X_test、y_test 数据集！\")\n",
    "\n",
    "# -------------------------- 目标函数（无早停+缩小参数范围） --------------------------\n",
    "def objective_xgb(trial):\n",
    "    param = {\n",
    "        # 核心：基于最优分布缩小搜索范围\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 530),  # 原500-600 → 500-530\n",
    "        'max_depth': trial.suggest_int('max_depth', 13, 14),          # 原12-15 → 13-14\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.23, 0.25),  # 原0.18-0.25 → 0.23-0.25\n",
    "        'subsample': trial.suggest_float('subsample', 0.88, 0.90),    # 原0.85-0.95 → 0.88-0.90\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.73, 0.75),  # 原0.65-0.75 → 0.73-0.75\n",
    "        'gamma': trial.suggest_float('gamma', 0.05, 0.10),             # 原0.05-0.3 → 0.05-0.10\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 8, 9),  # 原8-10 → 8-9\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 4.7, 4.9),      # 原4.5-5.5 → 4.7-4.9\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 3.3, 3.5),    # 原3.0-4.0 → 3.3-3.5\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'auc',\n",
    "        'n_jobs': 4  # 限制线程数\n",
    "    }\n",
    "\n",
    "    auc_scores = []\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        # 兼容DataFrame和numpy数组索引\n",
    "        if hasattr(X_train_resampled, 'iloc'):\n",
    "            X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[val_idx]\n",
    "        else:\n",
    "            X_train_fold, X_val_fold = X_train_resampled[train_idx], X_train_resampled[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train_resampled[train_idx], y_train_resampled[val_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(**param)\n",
    "        \n",
    "        # 核心：仅保留基础训练参数，无任何早停逻辑\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],  # 保留验证集计算AUC，不影响训练\n",
    "            verbose=False  # 关闭冗余的训练日志输出\n",
    "        )\n",
    "\n",
    "        # 计算验证集AUC（调优的核心指标）\n",
    "        y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# -------------------------- 启动Optuna调优 --------------------------\n",
    "print('开始XGBoost参数优化（缩小范围+无早停）...')\n",
    "study_xgb = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),  # 保留Optuna剪枝，提前终止差的试验\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# 范围缩小后，20次trial足够找到更优参数\n",
    "study_xgb.optimize(objective_xgb, n_trials=20, n_jobs=2)\n",
    "\n",
    "# -------------------------- 输出最优结果 --------------------------\n",
    "print(f\"\\n【最优交叉验证AUC】: {study_xgb.best_value:.6f}\")\n",
    "print(\"【最优参数】:\")\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# -------------------------- 训练最终模型（无早停+关闭日志） --------------------------\n",
    "best_params_xgb = study_xgb.best_params\n",
    "best_params_xgb.update({\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1  # 最终模型用全线程加速\n",
    "})\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(** best_params_xgb)\n",
    "\n",
    "# 最终模型训练也无早停逻辑\n",
    "xgb_model.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    eval_set=[(X_test, y_test)],  # 保留测试集评估指标\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# -------------------------- 评估测试集 --------------------------\n",
    "y_test_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_auc = roc_auc_score(y_test, y_test_pred_proba_xgb)\n",
    "print(f\"\\n【测试集最终AUC】: {xgb_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "with open('xgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "# 保存最佳参数\n",
    "with open('xgb_best_params.json', 'w') as f:\n",
    "    json.dump(best_params_xgb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LightGBM模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 16:02:04,313] A new study created in memory with name: no-name-fae5dda7-be4d-45b1-856b-0ae3b8aab2ce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始LightGBM参数优化...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 16:02:13,441] Trial 0 finished with value: 0.8039115865367508 and parameters: {'n_estimators': 411, 'max_depth': 8, 'learning_rate': 0.10243774399350054, 'subsample': 0.947319491588874, 'colsample_bytree': 0.6045739672105842, 'reg_alpha': 0.8942885100804299, 'reg_lambda': 0.07062078083064471, 'num_leaves': 55, 'min_child_samples': 90}. Best is trial 0 with value: 0.8039115865367508.\n",
      "[I 2025-11-20 16:02:28,215] Trial 1 finished with value: 0.7841863071596235 and parameters: {'n_estimators': 477, 'max_depth': 14, 'learning_rate': 0.027006766786775348, 'subsample': 0.8247377010707932, 'colsample_bytree': 0.6642981746918198, 'reg_alpha': 3.3525612060862575, 'reg_lambda': 7.265601515190201, 'num_leaves': 82, 'min_child_samples': 30}. Best is trial 0 with value: 0.8039115865367508.\n",
      "[I 2025-11-20 16:02:32,841] Trial 2 finished with value: 0.7720567788557356 and parameters: {'n_estimators': 193, 'max_depth': 8, 'learning_rate': 0.07420569937182112, 'subsample': 0.863979111617436, 'colsample_bytree': 0.8192227657425971, 'reg_alpha': 0.2824029714498322, 'reg_lambda': 4.289751660938022, 'num_leaves': 68, 'min_child_samples': 90}. Best is trial 0 with value: 0.8039115865367508.\n",
      "[I 2025-11-20 16:02:41,170] Trial 3 finished with value: 0.8182559168633828 and parameters: {'n_estimators': 469, 'max_depth': 6, 'learning_rate': 0.24279256314308958, 'subsample': 0.6169860332975946, 'colsample_bytree': 0.9224190010764645, 'reg_alpha': 3.000488812483667, 'reg_lambda': 4.5658150374928965, 'num_leaves': 53, 'min_child_samples': 96}. Best is trial 3 with value: 0.8182559168633828.\n",
      "[I 2025-11-20 16:02:44,562] Trial 4 finished with value: 0.7230559728851731 and parameters: {'n_estimators': 392, 'max_depth': 3, 'learning_rate': 0.15835249757271438, 'subsample': 0.8820449560689764, 'colsample_bytree': 0.8182229471418265, 'reg_alpha': 4.4772544917030155, 'reg_lambda': 1.8064814799331075, 'num_leaves': 65, 'min_child_samples': 31}. Best is trial 3 with value: 0.8182559168633828.\n",
      "[I 2025-11-20 16:03:17,062] Trial 5 finished with value: 0.8602586266282648 and parameters: {'n_estimators': 955, 'max_depth': 12, 'learning_rate': 0.23039886882235583, 'subsample': 0.7412249549346409, 'colsample_bytree': 0.9085509434204966, 'reg_alpha': 6.683574212703574, 'reg_lambda': 5.4767579943316, 'num_leaves': 90, 'min_child_samples': 93}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:03:28,150] Trial 6 finished with value: 0.8222328767627539 and parameters: {'n_estimators': 628, 'max_depth': 14, 'learning_rate': 0.25726541254113594, 'subsample': 0.9902194636974623, 'colsample_bytree': 0.7118787902067585, 'reg_alpha': 8.225836644424197, 'reg_lambda': 9.248204632860197, 'num_leaves': 37, 'min_child_samples': 58}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:03:33,981] Trial 7 finished with value: 0.7788330096655117 and parameters: {'n_estimators': 422, 'max_depth': 5, 'learning_rate': 0.15950079540334533, 'subsample': 0.8092003341695082, 'colsample_bytree': 0.9492662557699824, 'reg_alpha': 0.2382343069357673, 'reg_lambda': 6.482743695952746, 'num_leaves': 77, 'min_child_samples': 69}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:03:46,090] Trial 8 finished with value: 0.8225505541442015 and parameters: {'n_estimators': 626, 'max_depth': 7, 'learning_rate': 0.18860126442628472, 'subsample': 0.9035299300129394, 'colsample_bytree': 0.7836294853694681, 'reg_alpha': 6.802557559476558, 'reg_lambda': 7.845963202446161, 'num_leaves': 49, 'min_child_samples': 56}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:03:50,018] Trial 9 finished with value: 0.7037218381387443 and parameters: {'n_estimators': 328, 'max_depth': 4, 'learning_rate': 0.0297623169086264, 'subsample': 0.9606110391967244, 'colsample_bytree': 0.8779550832512286, 'reg_alpha': 5.7220352400889, 'reg_lambda': 2.7212216719244187, 'num_leaves': 37, 'min_child_samples': 42}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:04:21,678] Trial 10 finished with value: 0.855797418299949 and parameters: {'n_estimators': 980, 'max_depth': 12, 'learning_rate': 0.2189371352808882, 'subsample': 0.6977854870176492, 'colsample_bytree': 0.9993683655551024, 'reg_alpha': 9.60353444995753, 'reg_lambda': 9.853155006243309, 'num_leaves': 100, 'min_child_samples': 12}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:04:50,234] Trial 11 finished with value: 0.8532324362660111 and parameters: {'n_estimators': 963, 'max_depth': 11, 'learning_rate': 0.2193176783411999, 'subsample': 0.6926278070069912, 'colsample_bytree': 0.9806057263877883, 'reg_alpha': 9.82449732707696, 'reg_lambda': 9.830352683872261, 'num_leaves': 98, 'min_child_samples': 11}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:05:12,833] Trial 12 finished with value: 0.8505946925138167 and parameters: {'n_estimators': 942, 'max_depth': 11, 'learning_rate': 0.29921421085540734, 'subsample': 0.725429317955709, 'colsample_bytree': 0.9985754315032672, 'reg_alpha': 9.83282384457591, 'reg_lambda': 6.250922451258242, 'num_leaves': 100, 'min_child_samples': 74}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:05:40,127] Trial 13 finished with value: 0.8570226057389382 and parameters: {'n_estimators': 814, 'max_depth': 12, 'learning_rate': 0.2854116725806315, 'subsample': 0.7395823774071657, 'colsample_bytree': 0.8990697483187026, 'reg_alpha': 7.765446691449574, 'reg_lambda': 8.395927028806227, 'num_leaves': 88, 'min_child_samples': 10}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:06:33,837] Trial 14 finished with value: 0.8561313448051797 and parameters: {'n_estimators': 802, 'max_depth': 10, 'learning_rate': 0.29992026778435743, 'subsample': 0.7529592875707763, 'colsample_bytree': 0.8875086955813412, 'reg_alpha': 7.373887728553125, 'reg_lambda': 5.481092612425016, 'num_leaves': 82, 'min_child_samples': 77}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:06:58,334] Trial 15 finished with value: 0.813109580970681 and parameters: {'n_estimators': 762, 'max_depth': 15, 'learning_rate': 0.26350127571123527, 'subsample': 0.6355514985638853, 'colsample_bytree': 0.8758346576046644, 'reg_alpha': 6.353035169292941, 'reg_lambda': 8.313175535223811, 'num_leaves': 22, 'min_child_samples': 43}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:08:26,503] Trial 16 finished with value: 0.854394345024464 and parameters: {'n_estimators': 825, 'max_depth': 13, 'learning_rate': 0.1916074383639355, 'subsample': 0.7660373859991146, 'colsample_bytree': 0.7586184625813921, 'reg_alpha': 8.064011644151236, 'reg_lambda': 3.646244888147651, 'num_leaves': 88, 'min_child_samples': 28}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:09:18,255] Trial 17 finished with value: 0.8389337726381232 and parameters: {'n_estimators': 681, 'max_depth': 10, 'learning_rate': 0.11620107062671794, 'subsample': 0.6657929814364523, 'colsample_bytree': 0.9225101233770643, 'reg_alpha': 4.981113782277663, 'reg_lambda': 5.792168754219718, 'num_leaves': 72, 'min_child_samples': 65}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:09:44,441] Trial 18 finished with value: 0.8540691872615984 and parameters: {'n_estimators': 882, 'max_depth': 12, 'learning_rate': 0.2694451335408825, 'subsample': 0.7829853367299219, 'colsample_bytree': 0.8518273274824886, 'reg_alpha': 8.542716350373135, 'reg_lambda': 8.580481239024978, 'num_leaves': 90, 'min_child_samples': 45}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:10:07,965] Trial 19 finished with value: 0.8541223606348411 and parameters: {'n_estimators': 695, 'max_depth': 9, 'learning_rate': 0.2248216669413075, 'subsample': 0.7259415590800142, 'colsample_bytree': 0.942633220974907, 'reg_alpha': 6.087346385138357, 'reg_lambda': 6.995073822811342, 'num_leaves': 90, 'min_child_samples': 100}. Best is trial 5 with value: 0.8602586266282648.\n",
      "[I 2025-11-20 16:10:33,366] Trial 20 finished with value: 0.8627802776654478 and parameters: {'n_estimators': 869, 'max_depth': 13, 'learning_rate': 0.19247652804975782, 'subsample': 0.8457482140797645, 'colsample_bytree': 0.8436104504536255, 'reg_alpha': 3.798672761643613, 'reg_lambda': 3.1170369626260905, 'num_leaves': 75, 'min_child_samples': 19}. Best is trial 20 with value: 0.8627802776654478.\n",
      "[I 2025-11-20 16:10:58,796] Trial 21 finished with value: 0.8643894580172248 and parameters: {'n_estimators': 867, 'max_depth': 13, 'learning_rate': 0.196007574421672, 'subsample': 0.8151936968788328, 'colsample_bytree': 0.8523461760913739, 'reg_alpha': 4.095765670075915, 'reg_lambda': 2.0476469222803537, 'num_leaves': 77, 'min_child_samples': 19}. Best is trial 21 with value: 0.8643894580172248.\n",
      "[I 2025-11-20 16:11:22,552] Trial 22 finished with value: 0.8640648261159705 and parameters: {'n_estimators': 877, 'max_depth': 15, 'learning_rate': 0.18777773015942867, 'subsample': 0.8500488347564008, 'colsample_bytree': 0.8489033256579759, 'reg_alpha': 3.613895065417614, 'reg_lambda': 1.5355170689246072, 'num_leaves': 76, 'min_child_samples': 22}. Best is trial 21 with value: 0.8643894580172248.\n",
      "[I 2025-11-20 16:11:45,736] Trial 23 finished with value: 0.8608709574169537 and parameters: {'n_estimators': 885, 'max_depth': 15, 'learning_rate': 0.17835585111721408, 'subsample': 0.8546441508328508, 'colsample_bytree': 0.8413437749583701, 'reg_alpha': 2.484057874792699, 'reg_lambda': 1.2991021984837965, 'num_leaves': 62, 'min_child_samples': 21}. Best is trial 21 with value: 0.8643894580172248.\n",
      "[I 2025-11-20 16:12:05,540] Trial 24 finished with value: 0.8498956208523761 and parameters: {'n_estimators': 718, 'max_depth': 14, 'learning_rate': 0.1282594990805723, 'subsample': 0.8254586819229734, 'colsample_bytree': 0.7335908728623466, 'reg_alpha': 3.9961505168518476, 'reg_lambda': 2.853607076028516, 'num_leaves': 74, 'min_child_samples': 22}. Best is trial 21 with value: 0.8643894580172248.\n",
      "[I 2025-11-20 16:12:32,983] Trial 25 finished with value: 0.8719787059352072 and parameters: {'n_estimators': 876, 'max_depth': 15, 'learning_rate': 0.1997576770286354, 'subsample': 0.914859086744174, 'colsample_bytree': 0.8477897996564947, 'reg_alpha': 1.8189730243432607, 'reg_lambda': 0.9710205052469383, 'num_leaves': 79, 'min_child_samples': 20}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:12:50,494] Trial 26 finished with value: 0.8565632217998385 and parameters: {'n_estimators': 564, 'max_depth': 15, 'learning_rate': 0.13900159461277872, 'subsample': 0.9244793012351132, 'colsample_bytree': 0.7887745663337103, 'reg_alpha': 1.8779553078683708, 'reg_lambda': 0.0564943302558607, 'num_leaves': 82, 'min_child_samples': 35}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:13:08,724] Trial 27 finished with value: 0.8638341875955204 and parameters: {'n_estimators': 751, 'max_depth': 13, 'learning_rate': 0.20510543809596973, 'subsample': 0.8946224782974853, 'colsample_bytree': 0.8078100379770399, 'reg_alpha': 1.4384286861047528, 'reg_lambda': 1.5919631329124107, 'num_leaves': 69, 'min_child_samples': 37}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:13:27,596] Trial 28 finished with value: 0.8590015807400029 and parameters: {'n_estimators': 872, 'max_depth': 15, 'learning_rate': 0.17096180613059644, 'subsample': 0.794928535360356, 'colsample_bytree': 0.860815915145316, 'reg_alpha': 2.3231640273253538, 'reg_lambda': 1.1321562903997338, 'num_leaves': 58, 'min_child_samples': 19}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:13:52,871] Trial 29 finished with value: 0.8527388318825688 and parameters: {'n_estimators': 997, 'max_depth': 14, 'learning_rate': 0.07294145023175082, 'subsample': 0.9372546561636528, 'colsample_bytree': 0.6099166999955427, 'reg_alpha': 1.2674463408668144, 'reg_lambda': 0.7109640442266536, 'num_leaves': 77, 'min_child_samples': 50}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:14:05,457] Trial 30 finished with value: 0.8142535929056361 and parameters: {'n_estimators': 623, 'max_depth': 13, 'learning_rate': 0.09322258665307681, 'subsample': 0.9817218408140551, 'colsample_bytree': 0.7715034428446419, 'reg_alpha': 5.484624135785871, 'reg_lambda': 2.1757966642283737, 'num_leaves': 46, 'min_child_samples': 23}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:14:24,512] Trial 31 finished with value: 0.8636162573973392 and parameters: {'n_estimators': 748, 'max_depth': 13, 'learning_rate': 0.20618217711970485, 'subsample': 0.884775153323357, 'colsample_bytree': 0.8394695277695953, 'reg_alpha': 1.091256812708564, 'reg_lambda': 0.6980047372579605, 'num_leaves': 68, 'min_child_samples': 38}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:14:50,342] Trial 32 finished with value: 0.8710226763796811 and parameters: {'n_estimators': 904, 'max_depth': 14, 'learning_rate': 0.2096391010192687, 'subsample': 0.9197428527693177, 'colsample_bytree': 0.8100930186881452, 'reg_alpha': 1.9189990198531648, 'reg_lambda': 1.2437034560067983, 'num_leaves': 81, 'min_child_samples': 27}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:15:16,140] Trial 33 finished with value: 0.863089554407658 and parameters: {'n_estimators': 914, 'max_depth': 14, 'learning_rate': 0.14292939534605875, 'subsample': 0.9168169662588563, 'colsample_bytree': 0.7382083630785784, 'reg_alpha': 3.002252787842627, 'reg_lambda': 2.2206787248203725, 'num_leaves': 82, 'min_child_samples': 29}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:15:20,918] Trial 34 finished with value: 0.8133919861845638 and parameters: {'n_estimators': 149, 'max_depth': 15, 'learning_rate': 0.2381071154779278, 'subsample': 0.8325826965203298, 'colsample_bytree': 0.817798289955407, 'reg_alpha': 3.555481006146492, 'reg_lambda': 0.6718104402436601, 'num_leaves': 80, 'min_child_samples': 26}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:15:48,016] Trial 35 finished with value: 0.8640804529701803 and parameters: {'n_estimators': 834, 'max_depth': 14, 'learning_rate': 0.17250664765134022, 'subsample': 0.8695512654608432, 'colsample_bytree': 0.8287583454080574, 'reg_alpha': 4.374561835812589, 'reg_lambda': 3.7396569497300733, 'num_leaves': 95, 'min_child_samples': 15}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:16:16,545] Trial 36 finished with value: 0.8600902807978302 and parameters: {'n_estimators': 819, 'max_depth': 11, 'learning_rate': 0.16361276651605683, 'subsample': 0.9514151443594956, 'colsample_bytree': 0.6908941573264334, 'reg_alpha': 4.614214827011944, 'reg_lambda': 3.7809321696702876, 'num_leaves': 95, 'min_child_samples': 15}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:16:26,731] Trial 37 finished with value: 0.8454802764209088 and parameters: {'n_estimators': 282, 'max_depth': 14, 'learning_rate': 0.24122583981091833, 'subsample': 0.8758231174176198, 'colsample_bytree': 0.8078414337149188, 'reg_alpha': 0.6127343555959262, 'reg_lambda': 4.61119408607872, 'num_leaves': 95, 'min_child_samples': 15}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:16:54,973] Trial 38 finished with value: 0.8693824658106692 and parameters: {'n_estimators': 939, 'max_depth': 14, 'learning_rate': 0.2034422030055052, 'subsample': 0.9680642311373682, 'colsample_bytree': 0.7583707474841924, 'reg_alpha': 2.7655400446666447, 'reg_lambda': 2.2148493120248887, 'num_leaves': 87, 'min_child_samples': 33}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:17:18,761] Trial 39 finished with value: 0.8557214225327844 and parameters: {'n_estimators': 908, 'max_depth': 7, 'learning_rate': 0.24796334276621612, 'subsample': 0.9955516440761167, 'colsample_bytree': 0.6445545831505465, 'reg_alpha': 2.491272253948107, 'reg_lambda': 2.389632762675382, 'num_leaves': 85, 'min_child_samples': 32}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:17:39,969] Trial 40 finished with value: 0.8652169757593573 and parameters: {'n_estimators': 947, 'max_depth': 13, 'learning_rate': 0.20837879060365538, 'subsample': 0.9696437216427878, 'colsample_bytree': 0.7591265071947191, 'reg_alpha': 1.9710829060622959, 'reg_lambda': 0.35563020338237417, 'num_leaves': 65, 'min_child_samples': 48}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:18:00,541] Trial 41 finished with value: 0.8649250918899343 and parameters: {'n_estimators': 930, 'max_depth': 13, 'learning_rate': 0.20478552239820325, 'subsample': 0.9616724923645259, 'colsample_bytree': 0.7472877900225073, 'reg_alpha': 1.9457155466856475, 'reg_lambda': 0.3424608137751708, 'num_leaves': 65, 'min_child_samples': 52}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:18:22,079] Trial 42 finished with value: 0.8646236154282889 and parameters: {'n_estimators': 939, 'max_depth': 12, 'learning_rate': 0.2116990730074076, 'subsample': 0.9634453636602753, 'colsample_bytree': 0.7528626727249071, 'reg_alpha': 1.8204908551998271, 'reg_lambda': 0.3726919686356803, 'num_leaves': 63, 'min_child_samples': 51}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:18:43,266] Trial 43 finished with value: 0.8595510491552648 and parameters: {'n_estimators': 981, 'max_depth': 14, 'learning_rate': 0.23235618179137785, 'subsample': 0.9681786193451022, 'colsample_bytree': 0.7168293736714526, 'reg_alpha': 3.01325291823575, 'reg_lambda': 0.008974528312066798, 'num_leaves': 55, 'min_child_samples': 60}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:19:04,961] Trial 44 finished with value: 0.8645861828459385 and parameters: {'n_estimators': 940, 'max_depth': 14, 'learning_rate': 0.15171859980002786, 'subsample': 0.9313277994591111, 'colsample_bytree': 0.7918363773976108, 'reg_alpha': 0.5886944970724624, 'reg_lambda': 1.2484824542211381, 'num_leaves': 68, 'min_child_samples': 51}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:19:24,940] Trial 45 finished with value: 0.86221062492868 and parameters: {'n_estimators': 997, 'max_depth': 12, 'learning_rate': 0.20718789030311174, 'subsample': 0.9780399129442366, 'colsample_bytree': 0.7066857971454821, 'reg_alpha': 0.0693242830480103, 'reg_lambda': 0.8629697383005516, 'num_leaves': 57, 'min_child_samples': 47}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:19:40,221] Trial 46 finished with value: 0.8527949325521134 and parameters: {'n_estimators': 784, 'max_depth': 10, 'learning_rate': 0.250939384248502, 'subsample': 0.9073423186225362, 'colsample_bytree': 0.7669683294355703, 'reg_alpha': 1.722264624017947, 'reg_lambda': 0.5066702518404553, 'num_leaves': 49, 'min_child_samples': 39}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:20:02,802] Trial 47 finished with value: 0.8613123787998541 and parameters: {'n_estimators': 922, 'max_depth': 11, 'learning_rate': 0.2227204500911593, 'subsample': 0.9466485835742783, 'colsample_bytree': 0.6705047934894927, 'reg_alpha': 2.309393664098613, 'reg_lambda': 1.7306512499670963, 'num_leaves': 70, 'min_child_samples': 83}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:20:10,055] Trial 48 finished with value: 0.7552259162831821 and parameters: {'n_estimators': 959, 'max_depth': 3, 'learning_rate': 0.2746343554789531, 'subsample': 0.9971494614015535, 'colsample_bytree': 0.7336972195507824, 'reg_alpha': 0.8208474391940404, 'reg_lambda': 1.16560162124095, 'num_leaves': 66, 'min_child_samples': 62}. Best is trial 25 with value: 0.8719787059352072.\n",
      "[I 2025-11-20 16:20:37,916] Trial 49 finished with value: 0.8705881832235072 and parameters: {'n_estimators': 913, 'max_depth': 13, 'learning_rate': 0.18665259875997792, 'subsample': 0.9438770045480347, 'colsample_bytree': 0.7771361897465916, 'reg_alpha': 2.819453727290751, 'reg_lambda': 0.206560310472648, 'num_leaves': 87, 'min_child_samples': 33}. Best is trial 25 with value: 0.8719787059352072.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM最佳参数:\n",
      "n_estimators: 876\n",
      "max_depth: 15\n",
      "learning_rate: 0.1997576770286354\n",
      "subsample: 0.914859086744174\n",
      "colsample_bytree: 0.8477897996564947\n",
      "reg_alpha: 1.8189730243432607\n",
      "reg_lambda: 0.9710205052469383\n",
      "num_leaves: 79\n",
      "min_child_samples: 20\n",
      "交叉验证最佳AUC: 0.8720\n",
      "LightGBM测试集 AUC: 0.7917\n"
     ]
    }
   ],
   "source": [
    "# LightGBM参数优化函数\n",
    "def objective_lgb(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # 5折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_train_resampled, y_train_resampled):\n",
    "        X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**param)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# 运行Optuna优化\n",
    "print('开始LightGBM参数优化...')\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "\n",
    "print('LightGBM最佳参数:')\n",
    "for key, value in study_lgb.best_params.items():\n",
    "    print('{}: {}'.format(key, value))\n",
    "\n",
    "print('交叉验证最佳AUC: {:.4f}'.format(study_lgb.best_value))\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "best_params_lgb = study_lgb.best_params\n",
    "best_params_lgb['random_state'] = 42\n",
    "best_params_lgb['verbose'] = -1\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**best_params_lgb)\n",
    "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 预测和评估\n",
    "y_test_pred_proba_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "lgb_auc = roc_auc_score(y_test, y_test_pred_proba_lgb)\n",
    "\n",
    "print('LightGBM测试集 AUC: {:.4f}'.format(lgb_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 保存模型\n",
    "with open('lgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)\n",
    "\n",
    "# 保存最佳参数\n",
    "with open('lgb_best_params.json', 'w') as f:\n",
    "    json.dump(best_params_lgb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 18:25:54,469] A new study created in memory with name: no-name-a3c83d5f-54d6-435f-ab91-c9a650f25f0c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始CatBoost参数微调（5次以内）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 18:32:16,177] Trial 0 finished with value: 0.8698226089374591 and parameters: {'n_estimators': 700, 'max_depth': 12, 'learning_rate': 0.1058954229672149, 'subsample': 0.7052271673323328, 'colsample_bylevel': 0.6807416702319337, 'reg_lambda': 3.570574415195616, 'min_child_samples': 70}. Best is trial 0 with value: 0.8698226089374591.\n",
      "[I 2025-11-20 18:37:52,029] Trial 1 finished with value: 0.8640145910800566 and parameters: {'n_estimators': 700, 'max_depth': 11, 'learning_rate': 0.09301796524321296, 'subsample': 0.7151403828025522, 'colsample_bylevel': 0.6785755728566395, 'reg_lambda': 3.2319055052563246, 'min_child_samples': 70}. Best is trial 0 with value: 0.8698226089374591.\n",
      "[I 2025-11-20 19:34:26,794] Trial 2 finished with value: 0.8639991305109911 and parameters: {'n_estimators': 650, 'max_depth': 11, 'learning_rate': 0.11284189014351063, 'subsample': 0.7401761089470932, 'colsample_bylevel': 0.6701912530901575, 'reg_lambda': 2.9909859830267895, 'min_child_samples': 85}. Best is trial 0 with value: 0.8698226089374591.\n",
      "[I 2025-11-20 19:41:32,558] Trial 3 finished with value: 0.8699366082067082 and parameters: {'n_estimators': 650, 'max_depth': 12, 'learning_rate': 0.11612879005438699, 'subsample': 0.7534834328845864, 'colsample_bylevel': 0.6887655251280405, 'reg_lambda': 3.750863688329549, 'min_child_samples': 75}. Best is trial 3 with value: 0.8699366082067082.\n",
      "[I 2025-11-20 19:46:10,402] Trial 4 finished with value: 0.8626077015297436 and parameters: {'n_estimators': 650, 'max_depth': 11, 'learning_rate': 0.11165585341385906, 'subsample': 0.7229069576949905, 'colsample_bylevel': 0.6758776372566969, 'reg_lambda': 3.819961141138905, 'min_child_samples': 75}. Best is trial 3 with value: 0.8699366082067082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost最佳参数:\n",
      "n_estimators: 650\n",
      "max_depth: 12\n",
      "learning_rate: 0.11612879005438699\n",
      "subsample: 0.7534834328845864\n",
      "colsample_bylevel: 0.6887655251280405\n",
      "reg_lambda: 3.750863688329549\n",
      "min_child_samples: 75\n",
      "交叉验证最佳AUC: 0.8699\n",
      "CatBoost测试集 AUC: 0.7881\n"
     ]
    }
   ],
   "source": [
    "from optuna.pruners import MedianPruner  \n",
    "\n",
    "def objective_catboost(trial):\n",
    "    # 核心修改：基于最优实验的参数，设置极小的微调范围（仅最优值附近）\n",
    "    param = {\n",
    "        # 最优值650，微调范围600-700，步长50（仅3个候选值）\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 600, 700, step=50),  \n",
    "        # 最优值11/12，微调范围11-12（仅2个候选值）\n",
    "        'max_depth': trial.suggest_int('max_depth', 11, 12),  \n",
    "        # 最优值0.0957/0.1262，微调范围0.09-0.13（窄区间）\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.09, 0.13),  \n",
    "        # 最优值0.7085/0.8033，微调范围0.70-0.82（窄区间）\n",
    "        'subsample': trial.suggest_float('subsample', 0.70, 0.82),  \n",
    "        # 最优值0.6725/0.6854，微调范围0.67-0.69（仅0.02的区间）\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.67, 0.69),  \n",
    "        # 最优值0.4288/4.8741，分两个小区间（覆盖两个最优值）\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.4, 5.0),  \n",
    "        # 最优值70/86，微调范围70-90（步长5，减少候选）\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 70, 90, step=5),  \n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        # 保留加速配置\n",
    "        'thread_count': -1,  # 使用所有CPU核心\n",
    "        'early_stopping_rounds': 50  # 验证集指标50轮不提升则早停\n",
    "    }\n",
    "    \n",
    "    # 可选：GPU加速（如有NVIDIA GPU，取消注释）\n",
    "    # param['task_type'] = 'GPU'\n",
    "    # param['gpu_ram_part'] = 0.8  # 分配80%的GPU显存\n",
    "\n",
    "    # 保留3折交叉验证（加速）\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_train_resampled, y_train_resampled):\n",
    "        X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[val_idx]\n",
    "        \n",
    "        model = cb.CatBoostClassifier(**param)\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_val_fold, y_val_fold),\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    # 计算平均AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    \n",
    "    # 剪枝机制（因试验次数少，实际剪枝概率低，可保留）\n",
    "    trial.report(mean_auc, step=0)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "    \n",
    "    return mean_auc\n",
    "\n",
    "# 运行Optuna优化\n",
    "print('开始CatBoost参数微调（5次以内）...')\n",
    "# 保留剪枝器（试验次数少，可简化为无剪枝，注释掉pruner即可）\n",
    "study_catboost = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=MedianPruner(n_warmup_steps=1)  # 仅前1个试验不剪枝\n",
    ")\n",
    "# 核心修改：将试验次数设为5次（也可改为3次，如n_trials=3）\n",
    "study_catboost.optimize(objective_catboost, n_trials=5)  \n",
    "\n",
    "print('CatBoost最佳参数:')\n",
    "for key, value in study_catboost.best_params.items():\n",
    "    print('{}: {}'.format(key, value))\n",
    "\n",
    "print('交叉验证最佳AUC: {:.4f}'.format(study_catboost.best_value))\n",
    "\n",
    "# 使用最佳参数训练最终模型（保留加速配置）\n",
    "best_params_catboost = study_catboost.best_params\n",
    "best_params_catboost.update({\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'thread_count': -1,\n",
    "    'early_stopping_rounds': 50\n",
    "    # 如有GPU，添加：'task_type': 'GPU', 'gpu_ram_part': 0.8\n",
    "})\n",
    "\n",
    "catboost_model = cb.CatBoostClassifier(**best_params_catboost)\n",
    "catboost_model.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    eval_set=(X_test, y_test),  # 最终训练加入测试集早停\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 预测和评估\n",
    "y_test_pred_proba_catboost = catboost_model.predict_proba(X_test)[:, 1]\n",
    "catboost_auc = roc_auc_score(y_test, y_test_pred_proba_catboost)\n",
    "\n",
    "print('CatBoost测试集 AUC: {:.4f}'.format(catboost_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "with open('catboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(catboost_model, f)\n",
    "\n",
    "# 保存最佳参数\n",
    "with open('catboost_best_params.json', 'w') as f:\n",
    "    json.dump(best_params_catboost, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 加权软投票集成方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于AUC的权重分配:\n",
      "XGBoost权重: 0.3331\n",
      "LightGBM权重: 0.3342\n",
      "CatBoost权重: 0.3327\n",
      "基于AUC权重的集成测试集 AUC: 0.8039\n",
      "基于用户权重的集成测试集 AUC: 0.8039\n",
      "Sklearn VotingClassifier测试集 AUC: 0.8039\n"
     ]
    }
   ],
   "source": [
    "# 方法1: 按AUC分数分配权重\n",
    "total_auc = xgb_auc + lgb_auc + catboost_auc\n",
    "weights_by_auc = [xgb_auc/total_auc, lgb_auc/total_auc, catboost_auc/total_auc]\n",
    "\n",
    "print('基于AUC的权重分配:')\n",
    "print('XGBoost权重: {:.4f}'.format(weights_by_auc[0]))\n",
    "print('LightGBM权重: {:.4f}'.format(weights_by_auc[1]))\n",
    "print('CatBoost权重: {:.4f}'.format(weights_by_auc[2]))\n",
    "\n",
    "# 方法2: 用户指定权重（可调整）\n",
    "user_weights = [0.33, 0.33, 0.34]  # 近似平均分配\n",
    "\n",
    "# 实现加权软投票集成\n",
    "def weighted_voting_predict(models, X, weights):\n",
    "    # 获取所有模型的预测概率\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "        predictions.append(y_pred_proba)\n",
    "    \n",
    "    # 加权平均\n",
    "    weighted_avg = np.zeros_like(predictions[0])\n",
    "    for i, pred in enumerate(predictions):\n",
    "        weighted_avg += pred * weights[i]\n",
    "    \n",
    "    return weighted_avg\n",
    "\n",
    "# 集成模型列表\n",
    "models = [xgb_model, lgb_model, catboost_model]\n",
    "\n",
    "# 使用AUC权重的集成预测\n",
    "y_test_pred_proba_ensemble_auc = weighted_voting_predict(models, X_test, weights_by_auc)\n",
    "ensemble_auc_auc = roc_auc_score(y_test, y_test_pred_proba_ensemble_auc)\n",
    "\n",
    "# 使用用户权重的集成预测\n",
    "y_test_pred_proba_ensemble_user = weighted_voting_predict(models, X_test, user_weights)\n",
    "ensemble_auc_user = roc_auc_score(y_test, y_test_pred_proba_ensemble_user)\n",
    "\n",
    "print('基于AUC权重的集成测试集 AUC: {:.4f}'.format(ensemble_auc_auc))\n",
    "print('基于用户权重的集成测试集 AUC: {:.4f}'.format(ensemble_auc_user))\n",
    "\n",
    "# 也可以使用sklearn的VotingClassifier\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model),\n",
    "        ('catboost', catboost_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=weights_by_auc\n",
    ").fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_test_pred_proba_voting = voting_ensemble.predict_proba(X_test)[:, 1]\n",
    "voting_auc = roc_auc_score(y_test, y_test_pred_proba_voting)\n",
    "\n",
    "print('Sklearn VotingClassifier测试集 AUC: {:.4f}'.format(voting_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 基于AUC权重的加权投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8329\n",
      "精确率(Precision): 0.4341\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4685\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n",
      "\n",
      "===== 基于用户权重的加权投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8332\n",
      "精确率(Precision): 0.4348\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4689\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n",
      "\n",
      "===== Sklearn VotingClassifier软投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8329\n",
      "精确率(Precision): 0.4341\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4685\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 保存集成模型性能\n",
    "ensemble_performance = {\n",
    "    'xgb_auc': xgb_auc,\n",
    "    'lgb_auc': lgb_auc,\n",
    "    'catboost_auc': catboost_auc,\n",
    "    'ensemble_auc_auc': ensemble_auc_auc,\n",
    "    'ensemble_auc_user': ensemble_auc_user,\n",
    "    'voting_auc': voting_auc\n",
    "}\n",
    "\n",
    "with open('ensemble_performance.json', 'w') as f:\n",
    "    json.dump(ensemble_performance, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 堆叠集成(Stacking)方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练堆叠集成模型...\n",
      "堆叠集成测试集 AUC: 0.8023\n",
      "ExtraTrees元模型堆叠集成测试集 AUC: 0.7791\n"
     ]
    }
   ],
   "source": [
    "# 实现堆叠集成\n",
    "class StackingEnsemble:\n",
    "    def __init__(self, base_models, meta_model, n_splits=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 使用分层K折交叉验证生成元特征\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 创建元特征矩阵\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        # 对每个基础模型进行训练并生成元特征\n",
    "        for i, base_model in enumerate(self.base_models):\n",
    "            for train_idx, val_idx in skf.split(X, y):\n",
    "                # 在训练折叠上训练基础模型\n",
    "                base_model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "                # 在验证折叠上生成预测概率作为元特征\n",
    "                meta_features[val_idx, i] = base_model.predict_proba(X.iloc[val_idx])[:, 1]\n",
    "        \n",
    "        # 使用元特征训练元模型\n",
    "        self.meta_model.fit(meta_features, y)\n",
    "        \n",
    "        # 在完整训练集上重新训练所有基础模型\n",
    "        for base_model in self.base_models:\n",
    "            base_model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # 生成测试集的元特征\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, base_model in enumerate(self.base_models):\n",
    "            meta_features[:, i] = base_model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # 使用元模型预测最终概率\n",
    "        return self.meta_model.predict_proba(meta_features)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 返回类别预测\n",
    "        return self.predict_proba(X)[:, 1] > 0.5\n",
    "\n",
    "# 使用逻辑回归作为元模型\n",
    "meta_model_logistic = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# 创建堆叠集成模型\n",
    "stacking_ensemble = StackingEnsemble(\n",
    "    base_models=[xgb_model, lgb_model, catboost_model],\n",
    "    meta_model=meta_model_logistic\n",
    ")\n",
    "\n",
    "# 训练堆叠集成模型\n",
    "print('训练堆叠集成模型...')\n",
    "stacking_ensemble.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 预测和评估\n",
    "y_test_pred_proba_stacking = stacking_ensemble.predict_proba(X_test)[:, 1]\n",
    "stacking_auc = roc_auc_score(y_test, y_test_pred_proba_stacking)\n",
    "\n",
    "print('堆叠集成测试集 AUC: {:.4f}'.format(stacking_auc))\n",
    "\n",
    "# 可选：使用ExtraTrees作为元模型\n",
    "meta_model_extratrees = ExtraTreesClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "stacking_ensemble_extratrees = StackingEnsemble(\n",
    "    base_models=[xgb_model, lgb_model, catboost_model],\n",
    "    meta_model=meta_model_extratrees\n",
    ")\n",
    "\n",
    "stacking_ensemble_extratrees.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_test_pred_proba_stacking_extra = stacking_ensemble_extratrees.predict_proba(X_test)[:, 1]\n",
    "stacking_auc_extra = roc_auc_score(y_test, y_test_pred_proba_stacking_extra)\n",
    "\n",
    "print('ExtraTrees元模型堆叠集成测试集 AUC: {:.4f}'.format(stacking_auc_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 更新性能记录\n",
    "ensemble_performance['stacking_auc'] = stacking_auc\n",
    "ensemble_performance['stacking_auc_extra'] = stacking_auc_extra\n",
    "\n",
    "with open('ensemble_performance.json', 'w') as f:\n",
    "    json.dump(ensemble_performance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 基于AUC权重的加权投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8329\n",
      "精确率(Precision): 0.4341\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4685\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n",
      "\n",
      "===== 基于用户权重的加权投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8332\n",
      "精确率(Precision): 0.4348\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4689\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n",
      "\n",
      "===== Sklearn VotingClassifier软投票集成 评估结果 =====\n",
      "AUC: 0.8039\n",
      "准确率(Accuracy): 0.8329\n",
      "精确率(Precision): 0.4341\n",
      "召回率(Recall): 0.5088\n",
      "F1分数(F1-Score): 0.4685\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.47      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n",
      "\n",
      "===== ExtraTrees元模型堆叠集成 评估结果 =====\n",
      "AUC: 0.7791\n",
      "准确率(Accuracy): 0.8173\n",
      "精确率(Precision): 0.3950\n",
      "召回率(Recall): 0.4929\n",
      "F1分数(F1-Score): 0.4386\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     20365\n",
      "           1       0.40      0.49      0.44      3447\n",
      "\n",
      "    accuracy                           0.82     23812\n",
      "   macro avg       0.65      0.68      0.66     23812\n",
      "weighted avg       0.84      0.82      0.83     23812\n",
      "\n",
      "\n",
      "===== 逻辑回归元模型堆叠集成 评估结果 =====\n",
      "AUC: 0.8023\n",
      "准确率(Accuracy): 0.8306\n",
      "精确率(Precision): 0.4280\n",
      "召回率(Recall): 0.5062\n",
      "F1分数(F1-Score): 0.4638\n",
      "\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     20365\n",
      "           1       0.43      0.51      0.46      3447\n",
      "\n",
      "    accuracy                           0.83     23812\n",
      "   macro avg       0.67      0.70      0.68     23812\n",
      "weighted avg       0.84      0.83      0.84     23812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "def evaluate_model(y_true, y_pred_proba, model_name=\"集成模型\", threshold=0.5):\n",
    "    \"\"\"\n",
    "    输入真实标签、预测概率，计算并打印分类指标\n",
    "    :param y_true: 真实标签数组\n",
    "    :param y_pred_proba: 正类预测概率数组\n",
    "    :param model_name: 模型名称（用于打印）\n",
    "    :param threshold: 分类阈值（默认0.5，不平衡数据可调整）\n",
    "    \"\"\"\n",
    "    # 将概率转换为类别预测（核心：概率≥阈值为正类1，否则为负类0）\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    # 计算核心指标\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    acc = accuracy_score(y_true, y_pred)  # 准确率\n",
    "    prec = precision_score(y_true, y_pred)  # 精确率\n",
    "    rec = recall_score(y_true, y_pred)  # 召回率\n",
    "    f1 = f1_score(y_true, y_pred)  # F1分数\n",
    "    \n",
    "    # 打印指标结果\n",
    "    print(f\"\\n===== {model_name} 评估结果 =====\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"准确率(Accuracy): {acc:.4f}\")\n",
    "    print(f\"精确率(Precision): {prec:.4f}\")\n",
    "    print(f\"召回率(Recall): {rec:.4f}\")\n",
    "    print(f\"F1分数(F1-Score): {f1:.4f}\")\n",
    "    \n",
    "    # 打印详细分类报告（包含各类别的精确率、召回率、F1）\n",
    "    print(\"\\n分类报告：\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# ===================== 对原有集成结果进行多指标评估 =====================\n",
    "# 1. 评估基于AUC权重的手动加权投票集成\n",
    "evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred_proba=y_test_pred_proba_ensemble_auc,\n",
    "    model_name=\"基于AUC权重的加权投票集成\"\n",
    ")\n",
    "\n",
    "# 2. 评估基于用户权重的手动加权投票集成\n",
    "evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred_proba=y_test_pred_proba_ensemble_user,\n",
    "    model_name=\"基于用户权重的加权投票集成\"\n",
    ")\n",
    "\n",
    "# 3. 评估sklearn的VotingClassifier集成\n",
    "evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred_proba=y_test_pred_proba_voting,\n",
    "    model_name=\"Sklearn VotingClassifier软投票集成\"\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred_proba=y_test_pred_proba_stacking_extra,\n",
    "    model_name=\"ExtraTrees元模型堆叠集成\"\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    y_true=y_test,\n",
    "    y_pred_proba=y_test_pred_proba_stacking,\n",
    "    model_name=\"逻辑回归元模型堆叠集成\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 比较不同集成方法的性能并可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型性能比较:\n",
      "                 模型     AUC\n",
      "4          加权集成(用户)  0.8039\n",
      "3         加权集成(AUC)  0.8039\n",
      "5  VotingClassifier  0.8039\n",
      "6    堆叠集成(Logistic)  0.8023\n",
      "1          LightGBM  0.7917\n",
      "0           XGBoost  0.7892\n",
      "2          CatBoost  0.7881\n",
      "7  堆叠集成(ExtraTrees)  0.7791\n"
     ]
    }
   ],
   "source": [
    "# 确保所有模型性能都已记录\n",
    "if 'stacking_auc' not in ensemble_performance:\n",
    "    ensemble_performance['stacking_auc'] = stacking_auc\n",
    "if 'stacking_auc_extra' not in ensemble_performance:\n",
    "    ensemble_performance['stacking_auc_extra'] = stacking_auc_extra\n",
    "\n",
    "# 整理性能数据\n",
    "model_names = ['XGBoost', 'LightGBM', 'CatBoost', \n",
    "              '加权集成(AUC)', '加权集成(用户)', 'VotingClassifier', \n",
    "              '堆叠集成(Logistic)', '堆叠集成(ExtraTrees)']\n",
    "aucs = [ensemble_performance['xgb_auc'],\n",
    "        ensemble_performance['lgb_auc'],\n",
    "        ensemble_performance['catboost_auc'],\n",
    "        ensemble_performance['ensemble_auc_auc'],\n",
    "        ensemble_performance['ensemble_auc_user'],\n",
    "        ensemble_performance['voting_auc'],\n",
    "        ensemble_performance['stacking_auc'],\n",
    "        ensemble_performance['stacking_auc_extra']]\n",
    "\n",
    "# 创建性能比较表格\n",
    "performance_df = pd.DataFrame({\n",
    "    '模型': model_names,\n",
    "    'AUC': aucs\n",
    "})\n",
    "\n",
    "# 按AUC降序排序\n",
    "performance_df = performance_df.sort_values('AUC', ascending=False)\n",
    "\n",
    "print('模型性能比较:')\n",
    "print(performance_df.round(4))\n",
    "\n",
    "\n",
    "\n",
    "# 保存性能比较结果\n",
    "performance_df.to_csv('model_performance_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化AUC性能\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='AUC', y='模型', data=performance_df)\n",
    "plt.title('不同模型的AUC性能比较')\n",
    "plt.xlabel('AUC分数')\n",
    "plt.ylabel('模型类型')\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 在柱状图上添加数值标签\n",
    "for i, v in enumerate(performance_df['AUC']):\n",
    "    plt.text(v + 0.005, i, '{:.4f}'.format(v), va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制ROC曲线比较\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 获取所有模型的ROC曲线数据\n",
    "models_to_compare = {\n",
    "    'XGBoost': y_test_pred_proba_xgb,\n",
    "    'LightGBM': y_test_pred_proba_lgb,\n",
    "    'CatBoost': y_test_pred_proba_catboost,\n",
    "    '加权集成(AUC)': y_test_pred_proba_ensemble_auc,\n",
    "    '堆叠集成': y_test_pred_proba_stacking\n",
    "}\n",
    "\n",
    "# 绘制每个模型的ROC曲线\n",
    "for name, y_pred_proba in models_to_compare.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, lw=2, label='{} (AUC = {:.4f})'.format(name, roc_auc))\n",
    "\n",
    "# 绘制随机猜测的对角线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('假正例率')\n",
    "plt.ylabel('真正例率')\n",
    "plt.title('不同模型的ROC曲线比较')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型: 加权集成(用户)，AUC: 0.8039\n"
     ]
    }
   ],
   "source": [
    "# 找出最佳模型\n",
    "best_model_name = performance_df.iloc[0]['模型']\n",
    "best_auc = performance_df.iloc[0]['AUC']\n",
    "\n",
    "print('最佳模型: {}，AUC: {:.4f}'.format(best_model_name, best_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最佳模型的预测\n",
    "if best_model_name == 'XGBoost':\n",
    "    best_pred_proba = y_test_pred_proba_xgb\n",
    "elif best_model_name == 'LightGBM':\n",
    "    best_pred_proba = y_test_pred_proba_lgb\n",
    "elif best_model_name == 'CatBoost':\n",
    "    best_pred_proba = y_test_pred_proba_catboost\n",
    "elif best_model_name == '加权集成(AUC)':\n",
    "    best_pred_proba = y_test_pred_proba_ensemble_auc\n",
    "elif best_model_name == '加权集成(用户)':\n",
    "    best_pred_proba = y_test_pred_proba_ensemble_user\n",
    "elif best_model_name == 'VotingClassifier':\n",
    "    best_pred_proba = y_test_pred_proba_voting\n",
    "elif best_model_name == '堆叠集成(Logistic)':\n",
    "    best_pred_proba = y_test_pred_proba_stacking\n",
    "else:  # 堆叠集成(ExtraTrees)\n",
    "    best_pred_proba = y_test_pred_proba_stacking_extra\n",
    "# 绘制混淆矩阵\n",
    "best_pred = (best_pred_proba > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('{}的混淆矩阵'.format(best_model_name))\n",
    "plt.xlabel('预测标签')\n",
    "plt.ylabel('真实标签')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结\n",
    "print('=== 模型集成总结 ===')\n",
    "print('1. 最佳单模型: {}，AUC: {:.4f}'.format(model_names[np.argmax(aucs[:3])], max(aucs[:3])))\n",
    "print('2. 最佳集成方法: {}，AUC: {:.4f}'.format(best_model_name, best_auc))\n",
    "print('3. 集成提升: {:.2f}%'.format((best_auc - max(aucs[:3])) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

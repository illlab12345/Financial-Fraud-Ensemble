# 财务舞弊识别数据预处理流程总结

本文档详细总结了财务舞弊识别数据预处理的四个主要步骤：数据集成、数据清洗、数据变换和数据归约，记录了每个步骤的实现方法、技术细节和处理结果。

## 1. 数据集成（Data Integration）

### 1.1 目标

将分散在多个Excel文件中的财务指标数据与违规信息数据进行整合，构建一个统一的数据集。

### 1.2 实现方法

通过`data_integration.py`脚本实现，主要步骤包括：

1. **配置文件路径和通用列**：设置数据集根目录，定义关键字段（股票代码、会计期间、报表类型）
2. **读取违规信息**：加载违规信息总表，提取股票代码、违规日期等关键信息
3. **读取财务指标**：按类别（盈利能力、偿债能力等）读取各个Excel文件中的财务指标
4. **构建违规标签**：基于违规日期与会计期间的关系，为每条财务记录添加违规标签（0/1）
5. **整合数据集**：将所有财务指标与违规标签合并成一个完整数据集
6. **保存结果**：将集成后的数据保存为CSV文件

### 1.3 处理结果

生成`integrated_data.csv`文件，包含以下关键信息：
- 基础字段：股票代码（Stkcd）、会计期间（Accper）、报表类型（Typrep）
- 违规标签：isviolation（0表示未违规，1表示违规）
- 各类财务指标：盈利能力、偿债能力、发展能力等多维度财务指标

## 2. 数据清洗（Data Cleaning）

### 2.1 目标

处理数据中的缺失值、异常值和冗余信息，提高数据质量。

### 2.2 实现方法

通过`data_cleaning.py`脚本实现，主要步骤包括：

1. **加载数据**：读取集成后的数据文件
2. **数据类型转换**：将会计期间转换为日期格式，确保数值型字段格式正确
3. **缺失值处理**：
   - 分析各字段缺失比例
   - 删除缺失比例过高的字段
   - 对剩余缺失值采用合适方法填充（如均值、中位数或0值）
4. **异常值处理**：
   - 使用统计方法（如IQR方法）识别异常值
   - 根据业务规则对异常值进行修正或平滑处理
5. **重复记录处理**：删除完全相同的重复记录
6. **数据筛选**：保留有效时间段和报表类型的数据
7. **保存结果**：将清洗后的数据保存为CSV文件

### 2.3 处理结果

生成`cleaned_data.csv`文件，数据质量得到显著提升：
- 删除了高缺失率的冗余字段
- 修复了异常值和错误数据类型
- 确保了数据的完整性和一致性

## 3. 数据变换（Data Transformation）

### 3.1 目标

通过特征工程创建新的衍生特征，对数据进行标准化和编码，使其适合机器学习模型训练。

### 3.2 实现方法

通过`data_transformation.py`脚本实现，主要步骤包括：

1. **加载清洗数据**：读取清洗后的数据集
2. **时间特征提取**：
   - 从会计期间提取年份和季度信息
   - 创建时间相关的衍生特征
3. **财务比率计算**：
   - 基于现有财务指标计算综合财务分数
   - 构建能够反映企业财务状况的综合指标
4. **分类特征编码**：
   - 对报表类型等分类变量进行数值编码
   - 转换为模型可处理的数值形式
5. **特征标准化**：
   - 对关键财务特征进行标准化处理
   - 确保不同量纲的特征具有可比性
6. **缺失值再次处理**：处理变换过程中可能产生的新缺失值
7. **保存结果**：将变换后的数据保存为CSV文件

### 3.3 处理结果

生成`transformed_data.csv`文件，包含：
- 原始关键字段：Stkcd、Accper、Typrep、isviolation
- 时间特征：year、quarter
- 编码后的分类特征：Typrep_encoded
- 计算的综合财务分数和比率
- 标准化后的数值特征

共119,060条记录，包含56个特征，违规样本比例为14.48%。

## 4. 数据归约（Data Reduction）

### 4.1 目标

通过特征选择和维度规约，减少数据维度，提高后续模型训练的效率和效果。

### 4.2 实现方法

通过`data_reduction.py`脚本实现，主要步骤包括：

1. **加载变换数据**：读取变换后的数据集
2. **特征相关性分析**：计算特征之间的相关系数矩阵
3. **高度相关特征移除**：删除相关系数过高的冗余特征
4. **基于统计的特征选择**：使用SelectKBest方法选择最重要的特征
5. **主成分分析（PCA）降维**：
   - 对筛选后的特征进行PCA降维
   - 保留能够解释大部分方差的主成分
6. **数据集整合**：将原始关键字段与降维后的特征合并
7. **保存结果**：将归约后的数据保存为CSV文件

### 4.3 处理结果

生成`reduced_data.csv`文件，处理过程详情：
- 从49个特征中移除20个高度相关的特征
- 使用SelectKBest选择前29个最重要特征
- 通过PCA降维生成24个主成分，解释方差比例达96.22%
- 保留了基础关键字段（Stkcd、Accper、Typrep、isviolation等）

最终数据集包含119,060条记录，31个特征，违规样本比例保持14.48%。

## 预处理流程的技术特点

1. **可移植性**：所有脚本使用相对路径，确保在不同环境中都能正常运行
2. **模块化设计**：每个预处理步骤独立封装，便于维护和扩展
3. **详细日志**：每个脚本运行过程中输出关键信息，便于监控和调试
4. **特征工程**：通过财务指标计算和时间特征提取，增强数据表现力
5. **降维优化**：在保持数据信息的同时有效减少维度，为后续建模提供高效输入

---

本文档全面总结了财务舞弊识别数据预处理的完整流程，为后续的数据分析和模型构建奠定了坚实的数据基础。